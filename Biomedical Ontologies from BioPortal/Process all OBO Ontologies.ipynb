{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse all Ontologies from Open Biological and Biomedical Ontology Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "In this cell, we import the following libraries:\n",
    "\n",
    "- `rdflib`: This library is used for working with RDF (Resource Description Framework) data.\n",
    "- `deque` from `collections`: This library provides a double-ended queue implementation.\n",
    "- `pprint` from `pprint`: This library is used for pretty-printing data structures.\n",
    "- `pandas` as `pd`: This library is used for data manipulation and analysis.\n",
    "- `os`: This library provides a way of using operating system dependent functionality.\n",
    "\n",
    "These libraries are necessary for the subsequent code execution in this Jupyter Notebook document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from collections import deque\n",
    "import pprint as pprint\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Path for Ontologies\n",
    "\n",
    "In this cell, we set the path for the ontologies. The path is specified as `./ontologies`, which means that the ontologies are located in a directory named \"ontologies\" in the current working directory.\n",
    "\n",
    "This path will be used in subsequent cells to load and process the ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './ontologies'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Maximum Depth of Concepts in an Ontology\n",
    "\n",
    "The following code defines a function `get_max_depth` that calculates the maximum depth of concepts in an ontology.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_depth(source_ontology):\n",
    "    g=rdflib.Graph()\n",
    "\n",
    "    try:\n",
    "        g.parse(os.path.join(PATH, source_ontology))\n",
    "        # Parse the ontology file\n",
    "\n",
    "    except:\n",
    "        print('FILE {} not found'.format(file))\n",
    "    \n",
    "    concepts = dict()\n",
    "    for s,p,o in g:    \n",
    "        if s.find('purl.obolibrary.org/obo') > 0:\n",
    "            if str(s) not in concepts:\n",
    "                concepts[str(s)] = 1\n",
    "        if o.find('purl.obolibrary.org/obo') > 0:\n",
    "            if str(o) not in concepts:\n",
    "                concepts[str(o)] = 1\n",
    "    \n",
    "    num_of_hier_rel = 0            \n",
    "    unhier = dict()\n",
    "    for s,p,o in g:\n",
    "        if p.find('rdf-schema#subClassOf') > 0:\n",
    "            if s.find('purl.obolibrary.org/obo') > 0 and o.find('purl.obolibrary.org/obo') > 0:\n",
    "                if str(s) not in unhier:\n",
    "                    unhier[str(s)] = list()\n",
    "                unhier[str(s)].append(str(o))\n",
    "                num_of_hier_rel += 1\n",
    "    # Cleaning\n",
    "    for key, value in unhier.items():\n",
    "        unhier[key] = list(set(value))\n",
    "                \n",
    "    LIMIT = 60\n",
    "    for concept, value in concepts.items():\n",
    "        queue = deque() \n",
    "        max_depth = value\n",
    "        queue.append({\"t\":concept,\"d\":value})\n",
    "        while len(queue) > 0:\n",
    "            dequeued = queue.popleft()\n",
    "            if dequeued[\"t\"] in unhier:\n",
    "                broaders = unhier[dequeued[\"t\"]]\n",
    "                new_depth = dequeued[\"d\"]+1\n",
    "                if new_depth > max_depth:\n",
    "                    max_depth = new_depth\n",
    "                if new_depth > LIMIT:\n",
    "                    break\n",
    "                for broader in broaders:\n",
    "                    queue.append({\"t\":broader,\"d\":dequeued[\"d\"]+1})\n",
    "\n",
    "        concepts[concept] = max_depth\n",
    "\n",
    "    list_of_depths = pd.DataFrame(list(concepts.items()), columns=['concept','depth'])\n",
    "    list_of_depths.sort_values('depth', inplace=True, ascending=False)\n",
    "\n",
    "    return {'ontology':source_ontology, \n",
    "            'num_concepts': len(concepts),\n",
    "            'num_of_hier_rel': num_of_hier_rel,\n",
    "            'most_deep_concept': list_of_depths.iloc[0]['concept'] if len(list_of_depths) > 0 else 'na', \n",
    "            'max_depth': list_of_depths.iloc[0]['depth'] if len(list_of_depths) > 0 else 0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Maximum Depth for Specific Ontology\n",
    "\n",
    "In this cell, we calculate the maximum depth of concepts in the \"vto.owl\" ontology using the `get_max_depth()` function. \n",
    "\n",
    "The result is then printed using the `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_max_depth(\"vto.owl\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add New Files to the List\n",
    "\n",
    "In this code, we use a loop to iterate through the files in the specified directory using `os.walk()`. For each file, we check if it has the extension \".owl\" and if it is not already in the `files` list. If both conditions are met, we append the file to the `files` list.\n",
    "\n",
    "This code allows us to add new files to the list of files for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(PATH):\n",
    "    for file in f:\n",
    "        if '.owl' in file and file not in files:\n",
    "            files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Files: {len(files)} \\n\\n Name of Files: {files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = 0\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    ind += 1\n",
    "    print('Processing {} -> {}'.format(ind,file))\n",
    "    result = get_max_depth(file)   \n",
    "    df = df.append(result,ignore_index=True)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ontology','num_concepts','num_of_hier_rel','most_deep_concept','max_depth']].to_csv('report_obo_ontologies_FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "for file in files:\n",
    "    ind += 1\n",
    "    print('Processing {} -> {}'.format(ind,file))\n",
    "    if len(df[df['ontology'] == file]):\n",
    "        continue\n",
    "    result = get_max_depth(file)   \n",
    "    df = df.append(result,ignore_index=True)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually add\n",
    "df = df.append({'ontology':'micro.owl', \n",
    "            'num_concepts': 0,\n",
    "            'num_of_hier_rel': 0,\n",
    "            'most_deep_concept': 'na', \n",
    "            'max_depth': 0}\n",
    "    ,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"max_depth\"], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('report_obo_ontologies_V1.0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './obo-ontologies'\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(PATH):\n",
    "    for file in f:\n",
    "        if '.owl' in file:\n",
    "            files.append(file)#os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Files with Missing Data\n",
    "\n",
    "In this code, we iterate through the list of files and check if the \"most_deep_concept\" column in the dataframe `df` for the corresponding ontology file is equal to 'na'. If it is, we process the file by calling the `get_max_depth()` function and printing the result.\n",
    "\n",
    "This code is used to handle files that have missing data in the \"most_deep_concept\" column and update the dataframe `df` with the new results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "for file in files:\n",
    "    ind += 1\n",
    "    try:\n",
    "        if df[df['ontology'] == file]['most_deep_concept'].iloc[0] == 'na':\n",
    "            print('Processing {} -> {}'.format(ind,file))\n",
    "            result = get_max_depth(file)   \n",
    "            #df = df.append(result,ignore_index=True)\n",
    "            print(result)\n",
    "    except IndexError:\n",
    "        print('ROW {} not found'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['ontology'] == file]['most_deep_concept'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
