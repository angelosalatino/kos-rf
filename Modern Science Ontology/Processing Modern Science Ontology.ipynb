{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Modern Science Ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "In this cell, we are importing the following libraries:\n",
    "\n",
    "- `json`: Used for working with JSON data.\n",
    "- `pandas`: Used for data structurization.\n",
    "- `deque` from `collections`: Used for creating a double-ended queue.\n",
    "- `Graph` and `plugin` from `rdflib`: Used for working with RDF data.\n",
    "- `SPARQLWrapper` from `SPARQLWrapper`: Used for querying RDF data using SPARQL.\n",
    "- `Serializer` from `rdflib.serializer`: Used for serializing RDF data.\n",
    "\n",
    "These libraries are necessary for the subsequent cells in this Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from rdflib import Graph, plugin\n",
    "from SPARQLWrapper import SPARQLWrapper\n",
    "from rdflib.serializer import Serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"ontology.ttl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Ontology\n",
    "\n",
    "In this cell, we are parsing the ontology file using the `Graph().parse()` method from the `rdflib` library. The ontology file is specified by the `input_file` variable, which contains the path to the ontology file.\n",
    "\n",
    "After parsing the ontology, we print the graph object `g` to display the parsed ontology.\n",
    "\n",
    "This step is necessary for further analysis and querying of the ontology data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph().parse(input_file, format='ttl')\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the Ontology\n",
    "\n",
    "In the following, we are querying the ontology using the `g.query()` method from the `rdflib` library. The query is specified in the SPARQL format and is used to count the number of classes in the ontology.\n",
    "\n",
    "The query selects all instances of the `owl:Class` and retrieves their labels using the `rdfs:label` property. The result is the count of classes, which is assigned to the variable `?at`.\n",
    "\n",
    "This step is necessary for further analysis and understanding of the ontology structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = g.query(\n",
    "    \"\"\"PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n",
    "       SELECT (count(?a) as ?at)\n",
    "       WHERE {\n",
    "       ?a a owl:Class .\n",
    "       ?a rdfs:label ?b .\n",
    "       }\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in qres:\n",
    "    print(row.at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsci_json = g.serialize(format='json-ld', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(modsci_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modsci = pd.read_json(modsci_json)\n",
    "modsci.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsci1 = modsci[[\"@id\",\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"]][modsci['@id'].str.contains(\"w3id\") \n",
    "                                                                            &\n",
    "                                                                            modsci['http://www.w3.org/2000/01/rdf-schema#subClassOf'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsci1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}\".format(len(modsci1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = dict()\n",
    "for index, row in modsci1.iterrows():\n",
    "        concepts[row['@id']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modsci1 = modsci1[[\"@id\",\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"]][~modsci1['@id'].str.contains(\"https://w3id.org/skgo/modsci#ModernScience\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhier = dict()\n",
    "max_length = 0\n",
    "for index, row in modsci1.iterrows():\n",
    "    length = 0\n",
    "    if row['@id'] not in unhier:\n",
    "        unhier[row['@id']] = list()\n",
    "    parents = row[\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"]\n",
    "    for parent in parents:\n",
    "        unhier[row['@id']].append(parent['@id'])\n",
    "        length += 1\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            print(\"{}: {} parents\".format(row['@id'], max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(json.dumps(unhier, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_depth(concepts, unhier):\n",
    "    for concept, value in concepts.items():\n",
    "        visited = set()\n",
    "        queue = deque()\n",
    "        max_depth = value\n",
    "        queue.append({\"t\": concept, \"d\": value})\n",
    "\n",
    "        while queue:\n",
    "            dequeued = queue.popleft()\n",
    "            concept_name = dequeued[\"t\"]\n",
    "            depth = dequeued[\"d\"]\n",
    "\n",
    "            if concept_name in visited:\n",
    "                continue\n",
    "\n",
    "            visited.add(concept_name)\n",
    "\n",
    "            if concept_name in unhier:\n",
    "                broaders = unhier[concept_name]\n",
    "                new_depth = depth + 1\n",
    "                if new_depth > max_depth:\n",
    "                    max_depth = new_depth\n",
    "                for broader in broaders:\n",
    "                    queue.append({\"t\": broader, \"d\": depth + 1})\n",
    "\n",
    "        concepts[concept] = max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_max_depth(concepts, unhier)\n",
    "print(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_depths = pd.DataFrame.from_dict(concepts, orient='index', columns=['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_depths.sort_values('depth', inplace=True, ascending=False)\n",
    "list_of_depths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(json.dumps(unhier,indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
