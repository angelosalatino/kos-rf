{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse KNOWMAK\n",
    "\n",
    "In this notebook, we will perform analysis on the KNOWMAK classification scheme. \n",
    "\n",
    "First, we will import the necessary libraries and modules, and then proceed with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "We start by importing the required libraries for our analysis. These include:\n",
    "\n",
    "- `deque` from the `collections` module for implementing a queue\n",
    "- `pandas` for data manipulation and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import deque\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"KNOWMAK.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file,\"r\") as file:\n",
    "    km = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ket = km[0]\n",
    "sgc = km[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing KET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = dict()\n",
    "topics = dict()\n",
    "narrowers = dict()\n",
    "broaders = dict()\n",
    "\n",
    "def get_nested_infos(tb,tc, keywords, topics, narrowers, broaders):\n",
    "    for child in tc:\n",
    "        if child[\"label\"] not in topics:\n",
    "            topics[child[\"label\"]] = True\n",
    "        for keyword in child[\"keywords\"]:\n",
    "            keywords[keyword] = True\n",
    "        for keyword in child[\"primaryKeywords\"]:\n",
    "            keywords[keyword] = True\n",
    "        for keyword in child[\"secondaryKeywords\"]:\n",
    "            keywords[keyword] = True\n",
    "        if tb not in narrowers:\n",
    "            narrowers[tb] = list()\n",
    "        narrowers[tb].append(child[\"label\"])\n",
    "        \n",
    "        if child[\"label\"] not in broaders:\n",
    "            broaders[child[\"label\"]] = list()\n",
    "        broaders[child[\"label\"]].append(tb)\n",
    "        \n",
    "        if len(child[\"children\"]) > 0:\n",
    "            get_nested_infos(child[\"label\"], child[\"children\"], keywords, topics, narrowers, broaders)\n",
    "        \n",
    "        \n",
    "get_nested_infos(ket[\"label\"],ket[\"children\"], keywords, topics, narrowers, broaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(narrowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(topics))\n",
    "print(len(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, broad in broaders.items():\n",
    "    #print(len(broad))\n",
    "    if (len(broad) > 1):\n",
    "        print(key, broad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(broaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhier = broaders\n",
    "concepts = topics\n",
    "for concept, value in concepts.items():\n",
    "    queue = deque() \n",
    "    max_depth = value\n",
    "    queue.append({\"t\":concept,\"d\":value})\n",
    "    while len(queue) > 0:\n",
    "        dequeued = queue.popleft()\n",
    "        if dequeued[\"t\"] in unhier:\n",
    "            broads = unhier[dequeued[\"t\"]]\n",
    "            new_depth = dequeued[\"d\"]+1\n",
    "            if new_depth > max_depth:\n",
    "                max_depth = new_depth\n",
    "            for broader in broads:\n",
    "                queue.append({\"t\":broader,\"d\":dequeued[\"d\"]+1})\n",
    "    \n",
    "    concepts[concept] = max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list_of_depths = pd.DataFrame.from_dict(concepts, orient='index', columns=['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_depths.sort_values('depth', inplace=True, ascending=False)\n",
    "list_of_depths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
