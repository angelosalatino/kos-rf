{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Medical Subject Headings (MeSH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "In this cell, we import the necessary libraries for our code. The libraries we import are:\n",
    "\n",
    "- `rdflib`: A library for working with RDF (Resource Description Framework) data.\n",
    "- `Graph`: A class from `rdflib` that represents an RDF graph.\n",
    "- `RDFS`: A namespace from `rdflib` that provides access to RDF Schema vocabulary.\n",
    "- `URIRef`: A class from `rdflib` that represents a URI reference.\n",
    "- `numpy`: A library for working with arrays and matrices.\n",
    "- `urllib3`: A library for making HTTP requests.\n",
    "\n",
    "These libraries are required for the code to function properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib.namespace import RDFS\n",
    "from rdflib import URIRef\n",
    "import rdflib\n",
    "import json\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"mesh2024.nt\" #path to MeSH RDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating RDF Graph\n",
    "\n",
    "In the following, we create an RDF graph using the `rdflib` library. The graph is initialised as an empty graph using the `Graph()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.parse(input_file, format=\"nt\")\n",
    "\n",
    "with open('mesh2024graph.ttl', 'wb') as f:\n",
    "    g.serialize(f, format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.parse('mesh2023graph.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicalDescriptors = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Topical Descriptors\n",
    "\n",
    "In this cell, we execute a SPARQL query to retrieve the distinct pairs of Topical Descriptors and their corresponding preferred Concepts from the RDF graph.\n",
    "\n",
    "The query selects the Topical Descriptors (`?td`) that are of type `<http://id.nlm.nih.gov/mesh/vocab#TopicalDescriptor>` and have a preferred Concept (`?concept`).\n",
    "\n",
    "The result of the query is stored in the variable `qres`.\n",
    "\n",
    "Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qres = g.query(\n",
    "    \"\"\"SELECT DISTINCT ?td ?concept\n",
    "       WHERE {\n",
    "          ?td a <http://id.nlm.nih.gov/mesh/vocab#TopicalDescriptor> .\n",
    "          ?td <http://id.nlm.nih.gov/mesh/vocab#preferredConcept> ?concept .\n",
    "       }\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gfp(string):\n",
    "    return string.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp(string):\n",
    "    return string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in qres:\n",
    "    td_key = gfp(row[0])\n",
    "    concept_value = gfp(row[1])\n",
    "    topicalDescriptors[td_key] = concept_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(topicalDescriptors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET CONCEPTS\n",
    "\n",
    "\n",
    "qres = g.query(\n",
    "\"\"\"SELECT ?sub ?pred ?obj\n",
    "   WHERE {\n",
    "      ?sub a <http://id.nlm.nih.gov/mesh/vocab#Concept> .\n",
    "      ?sub ?pred ?obj .\n",
    "   }\"\"\")\n",
    "\n",
    "\n",
    "for row in qres:\n",
    "    \n",
    "    concept = gfp(row[0])\n",
    "    predicate = str(row[1])\n",
    "    t_object = gfp(row[2])\n",
    "    if concept not in concepts:\n",
    "        concepts[concept] = dict()\n",
    "\n",
    "    if predicate == \"http://id.nlm.nih.gov/mesh/vocab#relatedConcept\":\n",
    "        if \"relatedConcept\" not in concepts[concept]:\n",
    "            concepts[concept][\"relatedConcept\"] = list()\n",
    "        concepts[concept][\"relatedConcept\"].append(t_object)\n",
    "\n",
    "\n",
    "    if predicate == \"http://id.nlm.nih.gov/mesh/vocab#term\":\n",
    "        if \"term\" not in concepts[concept]:\n",
    "            concepts[concept][\"term\"] = list()\n",
    "        concepts[concept][\"term\"].append(t_object)\n",
    "\n",
    "    if predicate == \"http://id.nlm.nih.gov/mesh/vocab#preferredTerm\":  \n",
    "        concepts[concept][\"preferredTerm\"] = t_object\n",
    "\n",
    "    if predicate == \"http://www.w3.org/2000/01/rdf-schema#label\":\n",
    "        concepts[concept][\"label\"] = t_object\n",
    "\n",
    "print(len(concepts))\n",
    "\n",
    "with open(\"mesh-concepts.json\", \"w\") as ff:\n",
    "    json.dump(concepts,ff, indent=4)\n",
    "    \n",
    "#Print samples\n",
    "print(concepts[\"M000616231\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET MESH TERMS\n",
    "meshTerms = dict()\n",
    "\n",
    "qres = g.query(\n",
    "    \"\"\"SELECT DISTINCT ?term ?label\n",
    "       WHERE {\n",
    "          ?term a <http://id.nlm.nih.gov/mesh/vocab#Term> .\n",
    "          ?term <http://id.nlm.nih.gov/mesh/vocab#prefLabel> ?label .\n",
    "          \n",
    "          FILTER (lang(?label) = 'en')\n",
    "       }\"\"\")\n",
    "\n",
    "for row in qres:\n",
    "    meshTerms[gfp(row[0])] = row[1]\n",
    "    \n",
    "len(meshTerms)\n",
    "\n",
    "with open(\"mesh-terms.json\", \"w\") as ff:\n",
    "    json.dump(meshTerms,ff, indent=4)\n",
    "\n",
    "#sample print\n",
    "print(meshTerms[\"T007269\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALTERNATIVE TERMS\n",
    "altMeshTerms = dict()\n",
    "qres = g.query(\n",
    "    \"\"\"SELECT DISTINCT ?term ?label\n",
    "       WHERE {\n",
    "          ?term a <http://id.nlm.nih.gov/mesh/vocab#Term> .\n",
    "          ?term <http://id.nlm.nih.gov/mesh/vocab#altLabel> ?label .\n",
    "          \n",
    "          FILTER (lang(?label) = 'en')\n",
    "       }\"\"\")\n",
    "\n",
    "for row in qres:\n",
    "    #print(gfp(row[0]), row[1])\n",
    "    subj = gfp(row[0])\n",
    "    if subj not in altMeshTerms:\n",
    "        altMeshTerms[subj] = list()\n",
    "    altMeshTerms[subj].append(row[1])\n",
    "    \n",
    "with open(\"mesh-alt-terms.json\", \"w\") as ff:\n",
    "    json.dump(meshTerms,ff, indent=4)\n",
    "    \n",
    "print(altMeshTerms[\"T000013\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST IN CASE YOU WANT TO RELOAD THEM\n",
    "\n",
    "RELOAD = False\n",
    "\n",
    "if RELOAD:\n",
    "    with open(\"mesh-topicalDescriptors.json\",'r') as ff:\n",
    "        topicalDescriptors = json.load(ff)\n",
    "    with open(\"mesh-concepts.json\", \"r\") as ff:\n",
    "        concepts = json.load(ff)\n",
    "    with open(\"mesh-terms.json\", \"r\") as ff:\n",
    "        meshTerms = json.load(ff)\n",
    "    with open(\"mesh-alt-terms.json\", \"r\") as ff:\n",
    "        altMeshTerms = json.load(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_topics = dict()\n",
    "mesh_topics_wu = dict()\n",
    "mesh_broaders = dict()\n",
    "mesh_narrowers = dict()\n",
    "mesh_same_as = dict()\n",
    "mesh_primary_labels = dict()\n",
    "mesh_primary_labels_wu = dict()\n",
    "mesh_topic_stems = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING BROADER - NARROWER\n",
    "\n",
    "narrowers = dict()\n",
    "broaders = dict()\n",
    "\n",
    "\n",
    "\n",
    "bd = rdflib.term.URIRef(\"http://id.nlm.nih.gov/mesh/vocab#broaderDescriptor\")\n",
    "for o, p, s in g.triples((None, bd, None)): ####### <- be careful o,p,s\n",
    "    #print(\"{} {}\".format(s,o))\n",
    "    subj = gfp(s)\n",
    "    obj = gfp(o)\n",
    "    if subj not in narrowers:\n",
    "        narrowers[subj] = list()\n",
    "    if obj not in broaders:\n",
    "        broaders[obj] = list()\n",
    "    \n",
    "    narrowers[subj].append(obj)\n",
    "    broaders[obj].append(subj)\n",
    "\n",
    "for key,value in broaders.items():\n",
    "    broaders[key] = list(np.unique(value))\n",
    "for key,value in narrowers.items():\n",
    "    narrowers[key] = list(np.unique(value)) \n",
    "\n",
    "print(len(broaders))\n",
    "print(len(narrowers))\n",
    "with open(\"mesh-broaders.json\", \"w\") as ff:\n",
    "    json.dump(broaders,ff, indent=4)\n",
    "with open(\"mesh-narrowers.json\", \"w\") as ff:\n",
    "    json.dump(narrowers,ff, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glotd(key, tp, cs, mt): #get_label_of_topicalDescriptor\n",
    "    \"\"\"\n",
    "    tp = topicalDescriptors\n",
    "    cs = concepts\n",
    "    mt = meshterms\n",
    "    \"\"\"\n",
    "    t_concept = tp[key]\n",
    "    if \"preferredTerm\" in concepts[t_concept]:\n",
    "        return str(mt[concepts[t_concept][\"preferredTerm\"]]).lower()\n",
    "    else:\n",
    "        return str(concepts[t_concept][\"label\"]).lower()\n",
    "#sample \n",
    "print(glotd(\"D002493\", topicalDescriptors, concepts, meshTerms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME-AS and PRIMARY LABELS CONSTRUCTION\n",
    "sim_labels = dict()\n",
    "for key, value in topicalDescriptors.items():\n",
    "    t_label = glotd(key, topicalDescriptors, concepts, meshTerms)\n",
    "    \n",
    "    sim_labels[t_label] = list()\n",
    "    \n",
    "    if concepts[topicalDescriptors[key]][\"preferredTerm\"] in altMeshTerms:\n",
    "        sim_labels[t_label] += [str(k).lower() for k in altMeshTerms[concepts[topicalDescriptors[key]][\"preferredTerm\"]]]\n",
    "    \n",
    "    if \"term\" in concepts[topicalDescriptors[key]]:\n",
    "        additional_terms = concepts[topicalDescriptors[key]][\"term\"]\n",
    "        sim_labels[t_label] += [str(meshTerms[k]).lower() for k in additional_terms]\n",
    "        for t_term in additional_terms:\n",
    "            if t_term in altMeshTerms:\n",
    "                sim_labels[t_label] += [str(k).lower() for k in altMeshTerms[t_term]]\n",
    "    \n",
    "    if \"relatedConcept\" in concepts[topicalDescriptors[key]]:\n",
    "        additional_concepts = concepts[topicalDescriptors[key]][\"relatedConcept\"]\n",
    "        for t_concept in additional_concepts:\n",
    "            sim_labels[t_label].append(concepts[t_concept][\"label\"].lower())\n",
    "            if \"term\" in concepts[t_concept]:\n",
    "                additional_terms = concepts[t_concept][\"term\"]\n",
    "                sim_labels[t_label] += [str(meshTerms[k]).lower() for k in additional_terms]\n",
    "                for t_term in additional_terms:\n",
    "                    if t_term in altMeshTerms:\n",
    "                        sim_labels[t_label] += [str(k).lower() for k in altMeshTerms[t_term]]\n",
    "    \n",
    "    \n",
    "    if len(sim_labels[t_label]) == 0:\n",
    "        del sim_labels[t_label]\n",
    "\n",
    "for key,value in sim_labels.items():\n",
    "    sim_labels[key] = list(np.unique(value))\n",
    "    \n",
    "#sample print\n",
    "print(sim_labels[\"prion proteins\"])\n",
    "with open(\"mesh-sim-labels.json\", \"w\") as ff:\n",
    "    json.dump(sim_labels,ff, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_as = dict()\n",
    "primary_labels = dict()\n",
    "for key, value in sim_labels.items():\n",
    "    t_list = value.copy()\n",
    "    t_list.append(key)\n",
    "    for item in t_list:\n",
    "        same_as[item] = [x for x in t_list if x != item]\n",
    "        primary_labels[item] = key\n",
    "        \n",
    "print(primary_labels[\"prp proteins\"])\n",
    "print(same_as[\"prp proteins\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(same_as[\"abdomen, acute\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in narrowers.items():\n",
    "    try:\n",
    "        mesh_narrowers[glotd(key, topicalDescriptors, concepts, meshTerms)] = [glotd(k, topicalDescriptors, concepts, meshTerms) for k in value]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    \n",
    "for key, value in broaders.items():\n",
    "    try:\n",
    "        mesh_broaders[glotd(key, topicalDescriptors, concepts, meshTerms)] = [glotd(k, topicalDescriptors, concepts, meshTerms) for k in value]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for key,value in mesh_narrowers.items():\n",
    "    mesh_narrowers[key] = list(np.unique(value))\n",
    "for key,value in mesh_broaders.items():\n",
    "    mesh_broaders[key] = list(np.unique(value))\n",
    "\n",
    "mesh_same_as = same_as\n",
    "mesh_primary_labels = primary_labels\n",
    "for key, value in mesh_primary_labels.items():\n",
    "    mesh_primary_labels_wu[key.replace(\" \", \"_\")] = value.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING LABELS\n",
    "\n",
    "labels = list(set(mesh_same_as).union(set(mesh_narrowers),set(mesh_broaders)))\n",
    "for label in labels:\n",
    "    mesh_topics[label] = True\n",
    "    mesh_topics_wu[label.replace(\" \", \"_\")] = label\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING TOPIC STEMS\n",
    "\n",
    "for topic in mesh_topics.keys():\n",
    "    if topic[:4] not in mesh_topic_stems:\n",
    "        mesh_topic_stems[topic[:4]] = list()\n",
    "    mesh_topic_stems[topic[:4]].append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING ALL BROADERS\n",
    "\n",
    "def get_all_brach(bb, topic):\n",
    "    all_broaders = list()\n",
    "    queue = deque() \n",
    "    queue.append(topic)\n",
    "    while len(queue) > 0:\n",
    "        dequeued = queue.popleft()\n",
    "        if dequeued in bb:\n",
    "            broaders = bb[dequeued]\n",
    "            for broader in broaders:\n",
    "                queue.append(broader)\n",
    "                all_broaders.append(broader)\n",
    "    \n",
    "    return list(set(all_broaders))\n",
    "\n",
    "mesh_all_broaders = dict()\n",
    "for key, value in mesh_broaders.items():\n",
    "    try:\n",
    "        mesh_all_broaders[key] = get_all_brach(mesh_broaders, key)\n",
    "        if key == \"hiv infections\":\n",
    "            print(mesh_all_broaders[key])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "#print sample\n",
    "print(mesh_all_broaders[list(mesh_all_broaders.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"hyperhidrosis\"#\"hiv infections\"\n",
    "print(\"broaders: {}\".format(mesh_broaders[topic]))\n",
    "print(\"narrowers: {}\".format(mesh_narrowers[topic]))\n",
    "print(\"ALL BROADERS: {}\".format(mesh_all_broaders[topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = dict()\n",
    "mesh[\"topics\"] = mesh_topics\n",
    "mesh[\"_topics\"] = mesh_topics_wu\n",
    "mesh[\"broaders\"] = mesh_broaders\n",
    "mesh[\"narrowers\"] = mesh_narrowers\n",
    "mesh[\"same_as\"] = mesh_same_as\n",
    "mesh[\"primary_labels\"] = mesh_primary_labels\n",
    "mesh[\"_primary_labels\"] = mesh_primary_labels_wu\n",
    "mesh[\"topic_stems\"] = mesh_topic_stems \n",
    "mesh[\"all_broaders\"] = mesh_all_broaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mesh22023-11.json','w') as file:\n",
    "    json.dump(mesh, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
